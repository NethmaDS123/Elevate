# skill_tasks.yaml
manage_skill_benchmark_task:
  description: |
    Technical execution flow:
    1. Raw resume text → Full technical parse (2 attempts if needed)
    2. Domain/role context → Current company benchmarks
    3. Gap analysis with priority matrix
    4. Time-bound action plan
    5. Quality assurance checks
  expected_output: |
    {
      "metadata": {
        "parse_quality": {
          "skills_extracted": <int>,
          "projects_analyzed": <int>,
          "parse_attempts": <int>
        },
        "benchmark_sources": [<company>, ...]
      },
      "overall_score": <int 0-100>,
      "benchmarks": [
        {
          "company": <str>,
          "coverage": <int>,
          "missing": [<str>, ...],
          "strengths": [<str>, ...]
        }, ...
      ],
      "gap_analysis": {
        "critical": [
          {
            "skill": <str>,
            "required_level": <str>,
            "current_level": <str>,
            "remediation": {
              "resources": [<str>, ...],
              "projects": [<str>, ...],
              "timeline": <str>
            }
          }, ...
        ],
        "recommended_upgrades": [<str>, ...]
      },
      "action_plan": {
        "immediate": [<str>, ...],
        "mid_term": [<str>, ...],
        "long_term": [<str>, ...]
      }
    }
  constraints:
    - Reject if <15 skills parsed after 2 attempts
    - Require version numbers for key technologies
    - Flag any conflicting skill assessments
